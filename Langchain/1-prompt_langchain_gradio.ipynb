{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MN2RMDvV8Tj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxZ1wr_vSu75",
        "outputId": "a2f49a36-4fc0-4c3a-d385-dc8a2d0390e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]= HUGGINGFACEHUB_API_TOKEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qAfnffYfVb4e"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate , HuggingFaceHub , LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tzeGCuUCWcbw"
      },
      "outputs": [],
      "source": [
        "template = \"\"\" Question :{questio}\n",
        "  Answer: Let's think step by step\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWBvbuIw5e9M",
        "outputId": "3d68266e-c24d-418b-84ce-e15968804500"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['questio'], template=\" Question :{questio}\\n  Answer: Let's think step by step\\n  \")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = PromptTemplate (template=template , input_variables= {'Qusetion'})\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8_Chy45yxT",
        "outputId": "2a7e5d38-46b7-476d-ef77-48100422e487"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "HuggingFaceHub(client=<InferenceClient(model='mistralai/Mixtral-8x7B-Instruct-v0.1', timeout=None)>, repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1', task='text-generation', model_kwargs={'temprature': 0.6, 'max_length ': 100})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = HuggingFaceHub(repo_id= 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
        "                     model_kwargs= {'temprature':0.6, 'max_length ': 100})\n",
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqwisuNoFGLM",
        "outputId": "25938f83-71c4-4b41-a846-686ee4a71dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is solar ?\n",
            "\n",
            "Solar energy is the energy that comes from the sun. It is a renewable source of energy that can be harnessed using a variety of technologies, such as solar panels, solar water heaters, and solar ovens. Solar energy can be used to generate electricity, heat water, and provide lighting. It is a clean and sustainable source of energy that can help reduce our reliance on fossil fuels and decrease our carbon footprint.\n",
            "\n",
            "There are two main types\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(\"what is solar ?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z_gs8pPQ6wfO"
      },
      "outputs": [],
      "source": [
        "def predict(input, history):\n",
        "\n",
        "  print(llm.invoke(input))\n",
        "  response = llm.invoke(input)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "xSQ4LR8_9VDi",
        "outputId": "c4070f8b-ae52-4eeb-e8a9-14cdf31f4245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://72e661e3be0b31d6ac.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://72e661e3be0b31d6ac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://72e661e3be0b31d6ac.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "demo = gr.ChatInterface(fn=predict, title=\"Echo Bot\")\n",
        "demo.launch(share=True,debug = True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
